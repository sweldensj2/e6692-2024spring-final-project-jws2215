{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "412e835f-7cd8-4361-bf3c-940c449b7b15",
   "metadata": {},
   "source": [
    "# Data Processing and Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eb23c32-3cf1-4f91-b3f2-ee770508d65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import Video, display\n",
    "\n",
    "from utils.pretrained_deployment import download_images, download_images2, download_images_with_resize, download_images_full_size\n",
    "from utils.display import *\n",
    "from utils.make_dataset_nyc_landmarks import make_nyc_dataset\n",
    "\n",
    "from bing_image_downloader import downloader\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# reload modules every 2 seconds to see changes in notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b1454-45dd-47cc-9017-de484f3e0f52",
   "metadata": {},
   "source": [
    "## Download the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18a88245-02c5-4c65-bca6-2d6e8ce5d3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[%] Downloading Images to /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/downloaded_images/empire_state_building_from_the_ground\n",
      "\n",
      "\n",
      "[!!]Indexing page: 1\n",
      "\n",
      "[%] Indexed 5 Images on Page 1.\n",
      "\n",
      "===============================================\n",
      "\n",
      "[%] Downloading Image #1 from https://c1.staticflickr.com/5/4092/5042429689_582d127a7f_z.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #2 from https://i.pinimg.com/originals/96/9b/bd/969bbdc56048c56de553ac908c20ac16.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #3 from https://blogs.voanews.com/tedlandphairsamerica/files/2012/05/02-from-ground-level-cmh1.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #4 from https://geographic.media/wp-content/uploads/us0012-1.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #5 from https://www.findingtheuniverse.com/wp-content/uploads/2020/07/Empire-State-Building-from-ground-level_by_Laurence-Norah-2.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "\n",
      "\n",
      "[%] Done. Downloaded 5 images.\n"
     ]
    }
   ],
   "source": [
    "def download_images(query, num_images, download_path):\n",
    "    downloader.download(query, limit=num_images, output_dir=download_path, adult_filter_off=True, force_replace=False)\n",
    "\n",
    "\n",
    "# classes = [\"empire_state_building\", \n",
    "# \"1_world_trade_center\", \n",
    "# \"chrysler_building\", \n",
    "# \"432_park_ave\", \n",
    "# \"statue_of_liberty\",\n",
    "# \"brooklyn_bridge\",\n",
    "# \"vessel_nyc\",\n",
    "# \"united_nations_building\",\n",
    "# \"grand_central_terminal\",\n",
    "# \"flatiron\"]\n",
    "\n",
    "queries = [\"empire_state_building_from_the_ground\", \n",
    "\"1_world_trade_center\", \n",
    "\"432_park_ave\", \n",
    "\"united_nations_building\",\n",
    "\"flatiron\"]\n",
    "\n",
    "classes = {\n",
    "    0: \"EmpireState\",\n",
    "    1: \"WTC\",\n",
    "    2: \"432ParkAve\",\n",
    "    3: \"UNBuilding\",\n",
    "    4: \"Flatiron\"\n",
    "}\n",
    "#Make sure the yaml file matches this ^^\n",
    "\n",
    "\n",
    "\n",
    "# query = 'empire_state_building_from_the_ground'\n",
    "num_images = 5  # Number of images to download\n",
    "download_path = \"./downloaded_images\"  # Target folder path\n",
    "for query in queries:\n",
    "    # download_images_with_resize(query, num_images, target_size=target_size)\n",
    "    # download_images_full_size(query, num_images, download_folder)\n",
    "    download_images(query, num_images, download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe57fa-1599-45d1-b49f-f6734e1e3cd4",
   "metadata": {},
   "source": [
    "# Add annotations using rectlabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379a170-e62f-44af-9c7a-da8d8269c5af",
   "metadata": {},
   "source": [
    "Use the available software to create the yolo annotations for each image. This will take some time so go ahead, put some podcasts and get cracking. The .txt files need to be saved in the same directory as the original images. Make sure that the labels are following the same classes dictionary that we have here or things will not go well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82348f35-1766-4006-a1a1-0d3169ffd4fc",
   "metadata": {},
   "source": [
    "# Place into valid and training folders, prepare yolo datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c59714a-d8df-4b97-afd8-827624b9919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: 432_park_ave\n",
      "Raw Name: Image_3\n",
      "Combo Name: 432_park_ave_Image_3\n",
      "Raw Name: Image_2\n",
      "Combo Name: 432_park_ave_Image_2\n",
      "Raw Name: Image_1\n",
      "Combo Name: 432_park_ave_Image_1\n",
      "Raw Name: Image_5\n",
      "Combo Name: 432_park_ave_Image_5\n",
      "Raw Name: Image_4\n",
      "Combo Name: 432_park_ave_Image_4\n",
      "Processing folder: united_nations_building\n",
      "Raw Name: Image_3\n",
      "Combo Name: united_nations_building_Image_3\n",
      "Raw Name: Image_2\n",
      "Combo Name: united_nations_building_Image_2\n",
      "Raw Name: Image_1\n",
      "Combo Name: united_nations_building_Image_1\n",
      "Raw Name: Image_5\n",
      "Combo Name: united_nations_building_Image_5\n",
      "Raw Name: Image_4\n",
      "Combo Name: united_nations_building_Image_4\n",
      "Processing folder: 1_world_trade_center\n",
      "Raw Name: Image_3\n",
      "Combo Name: 1_world_trade_center_Image_3\n",
      "Raw Name: Image_2\n",
      "Combo Name: 1_world_trade_center_Image_2\n",
      "Raw Name: Image_1\n",
      "Combo Name: 1_world_trade_center_Image_1\n",
      "Raw Name: Image_5\n",
      "Combo Name: 1_world_trade_center_Image_5\n",
      "Raw Name: Image_4\n",
      "Combo Name: 1_world_trade_center_Image_4\n",
      "Processing folder: empire_state_building_from_the_ground\n",
      "Raw Name: Image_3\n",
      "Combo Name: empire_state_building_from_the_ground_Image_3\n",
      "Raw Name: Image_2\n",
      "Combo Name: empire_state_building_from_the_ground_Image_2\n",
      "Raw Name: Image_1\n",
      "Combo Name: empire_state_building_from_the_ground_Image_1\n",
      "Raw Name: Image_5\n",
      "Combo Name: empire_state_building_from_the_ground_Image_5\n",
      "Raw Name: Image_4\n",
      "Combo Name: empire_state_building_from_the_ground_Image_4\n",
      "Processing folder: flatiron\n",
      "Raw Name: Image_3\n",
      "Combo Name: flatiron_Image_3\n",
      "Raw Name: Image_2\n",
      "Combo Name: flatiron_Image_2\n",
      "Raw Name: Image_1\n",
      "Combo Name: flatiron_Image_1\n",
      "Raw Name: Image_5\n",
      "Combo Name: flatiron_Image_5\n",
      "Raw Name: Image_4\n",
      "Combo Name: flatiron_Image_4\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "# ONLY RUN IF YOU WANT DELETE CURRENT DATA AND REMAKE SET\n",
    "#########################################################\n",
    "\n",
    "fraction_valid = 0.25\n",
    "train_path = \"./datasets/nyc_landmarks/train\"\n",
    "valid_path = \"./datasets/nyc_landmarks/valid\"\n",
    "\n",
    "make_nyc_dataset(\n",
    "    download_path,\n",
    "    train_path = train_path,\n",
    "    val_path = valid_path,\n",
    "    label_dictionary = classes,\n",
    "    fraction_valid = fraction_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f3738-89ff-46ca-84d3-a005b6c3344b",
   "metadata": {},
   "source": [
    "## Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327904b-6c6b-42f0-bafe-89158e4d9aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0dee0bf-05b4-4723-8ad9-1aa8b30e143b",
   "metadata": {},
   "source": [
    "# Train Yolov9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9707d421-f856-408c-8f2f-20e074d962de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov9c.pt to 'yolov9c.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49.4M/49.4M [00:05<00:00, 9.79MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv9c summary: 618 layers, 25590912 parameters, 0 gradients, 104.0 GFLOPs\n",
      "Ultralytics YOLOv8.1.29 🚀 Python-3.11.7 torch-2.2.1 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov9c.pt, data=dataset.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    212864  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 1]        \n",
      "  3                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      "  4                  -1  1    847616  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 1]       \n",
      "  5                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  6                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
      "  7                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  8                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPELAN         [512, 512, 256]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    912640  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 1]      \n",
      " 16                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1   2988544  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 1]       \n",
      " 19                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
      " 22        [15, 18, 21]  1   5586655  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \n",
      "YOLOv9c summary: 618 layers, 25533087 parameters, 25533071 gradients, 103.7 GFLOPs\n",
      "\n",
      "Transferred 931/937 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/train... 20 images, 0 backgrounds, 0 corrupt: 100%|██████████| 20/20 [00:00<00:00, 129.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/valid... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 4700.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/valid.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      1.506       5.19      1.773         12        640: 100%|██████████| 2/2 [01:04<00:00, 32.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          5   0.000362        0.2    0.00474    0.00237\n",
      "\n",
      "1 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 51.6MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 51.6MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.29 🚀 Python-3.11.7 torch-2.2.1 CPU (Apple M2)\n",
      "YOLOv9c summary (fused): 384 layers, 25323103 parameters, 0 gradients, 102.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          5   0.000361        0.2    0.00498    0.00249\n",
      "           EmpireState          5          1          0          0          0          0\n",
      "                   WTC          5          1          0          0          0          0\n",
      "            432ParkAve          5          1          0          0          0          0\n",
      "            UNBuilding          5          1    0.00181          1     0.0249     0.0124\n",
      "              Flatiron          5          1          0          0          0          0\n",
      "Speed: 1.1ms preprocess, 556.1ms inference, 0.0ms loss, 15.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Build a YOLOv9c model from pretrained weight\n",
    "model = YOLO('yolov9c.pt')\n",
    "\n",
    "# Display model information (optional)\n",
    "model.info()\n",
    "\n",
    "# Train model\n",
    "results = model.train(data='dataset.yaml', epochs=1, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ad55e-4ec5-49ee-8bf0-8857f12a723a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "809c5bf3-9494-4dcd-aea0-494aaf4b8da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/5 /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/valid/1_world_trade_center_Image_3.jpg: 640x448 (no detections), 340.7ms\n",
      "image 2/5 /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/valid/432_park_ave_Image_3.jpg: 640x448 (no detections), 329.4ms\n",
      "image 3/5 /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/valid/empire_state_building_from_the_ground_Image_3.jpg: 640x448 (no detections), 329.0ms\n",
      "image 4/5 /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/valid/flatiron_Image_3.jpg: 640x448 (no detections), 314.0ms\n",
      "image 5/5 /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/valid/united_nations_building_Image_3.jpg: 480x640 (no detections), 348.1ms\n",
      "Speed: 1.5ms preprocess, 332.2ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict bounding boxes on validation data\n",
    "results = model.predict(valid_path)\n",
    "\n",
    "\n",
    "# for result in results:\n",
    "#     print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd3b04-7682-411a-94ec-56775ab6f086",
   "metadata": {},
   "source": [
    "# Train RT-DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44214066-4aaf-405e-9447-f0d27989b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/rtdetr-l.pt to 'rtdetr-l.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63.4M/63.4M [00:08<00:00, 8.11MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt-detr-l summary: 673 layers, 32970476 parameters, 0 gradients, 108.3 GFLOPs\n",
      "Ultralytics YOLOv8.1.29 🚀 Python-3.11.7 torch-2.2.1 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=rtdetr-l.pt, data=dataset.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "WARNING ⚠️ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7312127  ultralytics.nn.modules.head.RTDETRDecoder    [5, [256, 256, 256]]          \n",
      "rt-detr-l summary: 673 layers, 32816351 parameters, 32816351 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/train.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|██████████| 20/20 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/johansweldens/Documents/EECS6692.DLoE/final_project/e6692-2024spring-final-project-jws2215/datasets/nyc_landmarks/valid.cache... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      1.016      40.07      1.353         12        640: 100%|██████████| 2/2 [01:16<00:00, 38.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          5          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/detect/train2/weights/last.pt, 66.2MB\n",
      "Optimizer stripped from runs/detect/train2/weights/best.pt, 66.2MB\n",
      "\n",
      "Validating runs/detect/train2/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.29 🚀 Python-3.11.7 torch-2.2.1 CPU (Apple M2)\n",
      "rt-detr-l summary: 498 layers, 31994015 parameters, 0 gradients, 103.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          5          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.9ms preprocess, 494.1ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import RTDETR\n",
    "\n",
    "# Load a COCO-pretrained RT-DETR-l model\n",
    "model = RTDETR('rtdetr-l.pt')\n",
    "\n",
    "# Display model information (optional)\n",
    "model.info()\n",
    "\n",
    "# Train model\n",
    "results = model.train(data='dataset.yaml', epochs=1, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8f865-5115-43b0-9de3-c894857431b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
